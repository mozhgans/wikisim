{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload\n",
    "\n",
    "import os\n",
    "import time;\n",
    "import json \n",
    "import requests\n",
    "import numpy as np\n",
    "        \n",
    "\n",
    "# %aimport wikipedia\n",
    "# %aimport calcsim\n",
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "\n",
    "from wikisim.config import *\n",
    "from wikisim.calcsim import *\n",
    "\n",
    "\n",
    "def generate_candidates(S, M, max_t=10, enforce=True):\n",
    "    candslist=[]\n",
    "    for m in M:\n",
    "        wid = title2id(m[1])\n",
    "        if wid is None:\n",
    "            raise Exception(m[1].encode('utf-8') + ' not found')\n",
    "        \n",
    "        clist = anchor2concept(S[m[0]])\n",
    "        clist = sorted(clist, key=lambda x: -x[1])\n",
    "\n",
    "        smooth=0    \n",
    "        trg = [(i,(c,f)) for i,(c,f) in enumerate(clist) if c==wid]\n",
    "        if not trg:\n",
    "            trg=[(len(clist), (wid,0))]\n",
    "            smooth=1\n",
    "\n",
    "            \n",
    "        clist = clist[:max_t]\n",
    "        if smooth==1 or trg[0][0]>=max_t: \n",
    "            if clist:\n",
    "                clist.pop()\n",
    "            clist.append(trg[0][1])\n",
    "        s = sum(c[1]+smooth for c in clist )        \n",
    "        clist = [(c,float(f+smooth)/s) for c,f in clist ]\n",
    "            \n",
    "        candslist.append(clist)\n",
    "    return  candslist \n",
    "\n",
    "def disambiguate(C, method, direction, op_method):\n",
    "        \n",
    "    if op_method == 'ilp':\n",
    "        return disambiguate_ilp(C, method, direction)\n",
    "    if op_method == 'ilp2':\n",
    "        return disambiguate_ilp_2(C, method, direction)\n",
    "    if  op_method == 'context1'  :\n",
    "        return contextdisamb_1(C, direction)\n",
    "    if  op_method == 'context2'  :\n",
    "        return contextdisamb_2(C, direction)\n",
    "    if  op_method == 'context3'  :\n",
    "        return contextdisamb_3(C, direction)\n",
    "    \n",
    "    if op_method == 'keyq':\n",
    "        return key_quad(C, method, direction)\n",
    "    \n",
    "    if  op_method == 'context4_1'  :\n",
    "        return contextdisamb_4(C, direction, 1)\n",
    "    if  op_method == 'context4_2'  :\n",
    "        return contextdisamb_4(C, direction, 2)\n",
    "    if  op_method == 'context4_3'  :\n",
    "        return contextdisamb_4(C, direction, 3)\n",
    "    if  op_method == 'context4_4'  :\n",
    "        return contextdisamb_4(C, direction, 4)\n",
    "    if  op_method == 'pcontext4_4'  :\n",
    "        return contextdisamb_4(C, direction, 4)\n",
    "    \n",
    "    if  op_method == 'tagme'  :\n",
    "        return tagme(C, method, direction)\n",
    "    if  op_method == 'tagme2'  :\n",
    "        return tagme(C, method, direction, True)\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "def disambiguate_driver(C, ws, method, direction, op_method):\n",
    "    ids = []\n",
    "    titles = []\n",
    "    \n",
    "    windows = [[start, min(start+ws, len(C))] for start in range(0,len(C),ws) ]\n",
    "    last = len(windows)\n",
    "    if last > 1 and windows[last-1][1]-windows[last-1][0]<3:\n",
    "        windows[last-2][1] = len(C)\n",
    "        windows.pop()\n",
    "        \n",
    "    for w in windows:\n",
    "        chunk_c = C[w[0]:w[1]]\n",
    "        chunk_ids, chunk_titles = disambiguate(chunk_c, method, direction, op_method)\n",
    "        ids += chunk_ids\n",
    "        titles += chunk_titles\n",
    "    return ids, titles     \n",
    "\n",
    "def get_tp(gold_titles, ids):\n",
    "    tp=0\n",
    "    for m,id2 in zip(gold_titles, ids):\n",
    "        if title2id(m[1]) == id2:\n",
    "            tp += 1\n",
    "    return [tp, len(ids)]\n",
    "\n",
    "def get_prec(tp_list):\n",
    "    if not tp_list:\n",
    "        return 0, 0\n",
    "    overall_tp = 0\n",
    "    overall_count=0\n",
    "    macro_prec = 0;\n",
    "    for tp, count in tp_list:\n",
    "        overall_tp += tp\n",
    "        overall_count += count\n",
    "        macro_prec += float(tp)/count\n",
    "        \n",
    "    macro_prec = macro_prec/len(tp_list)\n",
    "    micro_prec = float(overall_tp)/overall_count\n",
    "    \n",
    "    return micro_prec, macro_prec\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from itertools import chain\n",
    "from itertools import product\n",
    "from itertools import combinations\n",
    "\n",
    "random.seed(7)\n",
    "#C = [('a','b','c'), ('h', 'i'),('h', 'i','j','j'),('g','l','a'),('o','o','p')]\n",
    "\n",
    "def getscore(x,y,method, direction):\n",
    "    return getsim(x,y ,method, direction)\n",
    "    #return random.random()\n",
    "\n",
    "def get_sim_matrix(candslist,method, direction):\n",
    "    concepts=  list(chain(*candslist))\n",
    "    concepts=  list(set(c[0] for c in concepts))\n",
    "    sims = pd.DataFrame(index=concepts, columns=concepts)\n",
    "    for cands1,cands2 in combinations(candslist,2):\n",
    "        for c1,c2 in product(cands1,cands2):\n",
    "            sims[c1[0]][c2[0]]= sims[c2[0]][c1[0]] = getscore(c1[0],c2[0] , method, direction)\n",
    "    return sims        \n",
    "\n",
    "#simmatrix = get_sim_matrix(C, 'method', 'direction')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# normla\n",
    "def key_criteria(x):\n",
    "    if len(x[1])==1 or x[1][1][1]==0:\n",
    "        return float(\"inf\")\n",
    "    \n",
    "    return (x[1][0][1]-x[1][1][1]) / x[1][1][1]\n",
    "\n",
    "def find_key_concept(candslist, cveclist_bdrs, cvec_arr, ver):\n",
    "    \n",
    "    aggr_cveclist = np.zeros(shape=(len(candslist),cvec_arr.shape[1]))\n",
    "    for i in range(len(cveclist_bdrs)):\n",
    "        b,e = cveclist_bdrs[i]\n",
    "        aggr_cveclist[i]=cvec_arr[b:e].sum(axis=0)\n",
    "    \n",
    "    from itertools import izip\n",
    "    resolved = 0\n",
    "    Dlist=[]        \n",
    "    for i in range(len(candslist)):\n",
    "        cands = candslist[i]\n",
    "        b,e = cveclist_bdrs[i]\n",
    "        cvec = cvec_arr[b:e]\n",
    "        convec=aggr_cveclist[:i].sum(axis=0) + aggr_cveclist[i+1:].sum(axis=0)\n",
    "        D=[]    \n",
    "        for v in cvec:\n",
    "            d = 1-sp.spatial.distance.cosine(convec, v);\n",
    "            if np.isnan(d):\n",
    "                d=0\n",
    "            D.append(d)\n",
    "        D=sorted(enumerate(D), key=lambda x: -x[1])\n",
    "        Dlist.append(D)\n",
    "\n",
    "    if ver ==1: \n",
    "        max_concept, _ = max(enumerate(Dlist), key=lambda x: x[1][0][1] if len(x[1])>1 else -1)\n",
    "    elif ver ==2: \n",
    "        max_concept, _ = max(enumerate(Dlist), key=lambda x: (x[1][0][1]-x[1][1][1]) if len(x[1])>1 else -1)\n",
    "    elif ver ==3: \n",
    "        max_concept, _ = max(enumerate(Dlist), key=lambda x: (x[1][0][1]-x[1][1][1])/(x[1][0][1]+x[1][1][1]) if len(x[1])>1 else -1)\n",
    "    elif ver ==4: \n",
    "        max_concept, _ = max(enumerate(Dlist), key=key_criteria)\n",
    "    max_candidate = Dlist[max_concept][0][0]\n",
    "    return max_concept, max_candidate\n",
    "\n",
    "\n",
    "def contextdisamb_4(candslist, direction=DIR_OUT, ver=1):\n",
    "    cframelist=[]\n",
    "    cveclist_bdrs = []\n",
    "    ambig_count=0\n",
    "    for cands in candslist:\n",
    "        if len(candslist)>1:\n",
    "            ambig_count += 1\n",
    "        cands_rep = [conceptrep(c[0], direction, get_titles=False) for c in cands]\n",
    "        cveclist_bdrs += [(len(cframelist), len(cframelist)+len(cands_rep))]\n",
    "        cframelist += cands_rep\n",
    "\n",
    "    #print \"ambig_count:\", ambig_count\n",
    "        \n",
    "    cvec_fr = pd.concat(cframelist, join='outer', axis=1)\n",
    "    cvec_fr.fillna(0, inplace=True)\n",
    "    cvec_arr = cvec_fr.as_matrix().T\n",
    "    i=0\n",
    "    for cframe in cframelist:\n",
    "        if cframe.empty:\n",
    "            cvec_arr = np.insert(cvec_arr,i,0, axis=0)\n",
    "        i+=1    \n",
    "    \n",
    "        \n",
    "    # find maximum ... \n",
    "        \n",
    "    max_concept, max_candidate = find_key_concept(candslist, cveclist_bdrs, cvec_arr, ver)\n",
    "    \n",
    "    b,e = cveclist_bdrs[max_concept]\n",
    "    \n",
    "    convec =  cvec_arr[b:e][max_candidate]\n",
    "        \n",
    "    \n",
    "    # Iterate \n",
    "    res=[]\n",
    "    for i in range(len(candslist)):\n",
    "        cands = candslist[i]\n",
    "        b,e = cveclist_bdrs[i]\n",
    "        cvec = cvec_arr[b:e]\n",
    "\n",
    "        maxd=-1\n",
    "        index = -1\n",
    "        mi=0\n",
    "\n",
    "        for v in cvec:\n",
    "            d = 1-sp.spatial.distance.cosine(convec, v);\n",
    "            if d>maxd:\n",
    "                maxd=d\n",
    "                index=mi\n",
    "            mi +=1\n",
    "        if index==-1:\n",
    "            index=0\n",
    "        #print i, index, maxd    \n",
    "        res.append(cands[index][0]) \n",
    "        b,e = cveclist_bdrs[i]\n",
    "        cveclist_bdrs[i] = (b+index,b+index+1)\n",
    "        \n",
    "        #aggr_cveclist[i] =  cvec_arr[b:e][index]\n",
    "        \n",
    "        candslist[i] = candslist[i][index][0]\n",
    "    titles = ids2title(res)\n",
    "\n",
    "    return res, titles        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#parallel\n",
    "def key_criteria(x):\n",
    "    if len(x[1])==1 or x[1][1][1]==0:\n",
    "        return float(\"inf\")\n",
    "    \n",
    "    return (x[1][0][1]-x[1][1][1]) / x[1][1][1]\n",
    "qfrom functools import partial\n",
    "\n",
    "def find_key_concept(candslist, cveclist_bdrs, cvec_arr, ver):\n",
    "    \n",
    "    aggr_cveclist = np.zeros(shape=(len(candslist),cvec_arr.shape[1]))\n",
    "    for i in range(len(cveclist_bdrs)):\n",
    "        b,e = cveclist_bdrs[i]\n",
    "        aggr_cveclist[i]=cvec_arr[b:e].sum(axis=0)\n",
    "    \n",
    "    from itertools import izip\n",
    "    resolved = 0\n",
    "    Dlist=[]        \n",
    "    for i in range(len(candslist)):\n",
    "        cands = candslist[i]\n",
    "        b,e = cveclist_bdrs[i]\n",
    "        cvec = cvec_arr[b:e]\n",
    "        convec=aggr_cveclist[:i].sum(axis=0) + aggr_cveclist[i+1:].sum(axis=0)\n",
    "        D=[]    \n",
    "        for v in cvec:\n",
    "            d = 1-sp.spatial.distance.cosine(convec, v);\n",
    "            if np.isnan(d):\n",
    "                d=0\n",
    "            D.append(d)\n",
    "        D=sorted(enumerate(D), key=lambda x: -x[1])\n",
    "        Dlist.append(D)\n",
    "\n",
    "    if ver ==1: \n",
    "        max_concept, _ = max(enumerate(Dlist), key=lambda x: x[1][0][1] if len(x[1])>1 else -1)\n",
    "    elif ver ==2: \n",
    "        max_concept, _ = max(enumerate(Dlist), key=lambda x: (x[1][0][1]-x[1][1][1]) if len(x[1])>1 else -1)\n",
    "    elif ver ==3: \n",
    "        max_concept, _ = max(enumerate(Dlist), key=lambda x: (x[1][0][1]-x[1][1][1])/(x[1][0][1]+x[1][1][1]) if len(x[1])>1 else -1)\n",
    "    elif ver ==4: \n",
    "        max_concept, _ = max(enumerate(Dlist), key=key_criteria)\n",
    "    max_candidate = Dlist[max_concept][0][0]\n",
    "    return max_concept, max_candidate\n",
    "\n",
    "\n",
    "def contextdisamb_4(candslist, direction=DIR_OUT, ver=1):\n",
    "    cframelist=[]\n",
    "    cveclist_bdrs = []\n",
    "    ambig_count=0\n",
    "    for cands in candslist:\n",
    "        if len(candslist)>1:\n",
    "            ambig_count += 1\n",
    "        cands_rep = [conceptrep(c[0], direction, get_titles=False) for c in cands]\n",
    "        cveclist_bdrs += [(len(cframelist), len(cframelist)+len(cands_rep))]\n",
    "        cframelist += cands_rep\n",
    "\n",
    "    #print \"ambig_count:\", ambig_count\n",
    "        \n",
    "    cvec_fr = pd.concat(cframelist, join='outer', axis=1)\n",
    "    cvec_fr.fillna(0, inplace=True)\n",
    "    cvec_arr = cvec_fr.as_matrix().T\n",
    "    i=0\n",
    "    for cframe in cframelist:\n",
    "        if cframe.empty:\n",
    "            cvec_arr = np.insert(cvec_arr,i,0, axis=0)\n",
    "        i+=1    \n",
    "    \n",
    "        \n",
    "    # find maximum ... \n",
    "        \n",
    "    max_concept, max_candidate = to(candslist, cveclist_bdrs, cvec_arr, ver)\n",
    "    \n",
    "    b,e = cveclist_bdrs[max_concept]\n",
    "    \n",
    "    convec =  cvec_arr[b:e][max_candidate]\n",
    "        \n",
    "    \n",
    "    # Iterate \n",
    "    res=[]\n",
    "    for i in range(len(candslist)):\n",
    "        cands = candslist[i]\n",
    "        b,e = cveclist_bdrs[i]\n",
    "        cvec = cvec_arr[b:e]\n",
    "\n",
    "        maxd=-1\n",
    "        index = -1\n",
    "        mi=0\n",
    "\n",
    "        for v in cvec:\n",
    "            d = 1-sp.spatial.distance.cosine(convec, v);\n",
    "            if d>maxd:\n",
    "                maxd=d\n",
    "                index=mi\n",
    "            mi +=1\n",
    "        if index==-1:\n",
    "            index=0\n",
    "        #print i, index, maxd    \n",
    "        res.append(cands[index][0]) \n",
    "        b,e = cveclist_bdrs[i]\n",
    "        cveclist_bdrs[i] = (b+index,b+index+1)\n",
    "        \n",
    "        #aggr_cveclist[i] =  cvec_arr[b:e][index]\n",
    "        \n",
    "        candslist[i] = candslist[i][index][0]\n",
    "    titles = ids2title(res)\n",
    "\n",
    "    return res, titles        \n",
    "\n",
    "\n",
    "\n",
    "ids = Pkey_quad(C, 'method', 'direction', simmatrix)\n",
    "print ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload\n",
    "\n",
    "# %aimport wsd\n",
    "# import sys\n",
    "from wsd import *\n",
    "import time\n",
    "S=[\"Major League Baseball\", \"New York City\", \"Major League Baseball\", \"American League\",\n",
    "            \"Boston Red Sox\", \"Seattle Mariners\", \"Cleveland Indians\", \"Milwaukee Brewers\", \"Baltimore Orioles\",\n",
    "            \"Oakland Athletics\", \"New York Yankees\", \"Chicago White Sox\", \"Toronto Blue Jays\", \"Texas Rangers\", \n",
    "            \"Minnesota Twins\", \"Detroit Tigers\", \"Kansas City Royals\"]\n",
    "M=[[0, \"Major_League_Baseball\"], [1, \"New_York_City\"], [2, \"Major_League_Baseball\"], [3, \"American_League\"],\n",
    "   [4, \"Boston_Red_Sox\"], [5, \"Seattle_Mariners\"], [6, \"Cleveland_Indians\"], [7, \"Milwaukee_Brewers\"],\n",
    "   [8, \"Baltimore_Orioles\"], [9, \"Oakland_Athletics\"], [10, \"New_York_Yankees\"], [11, \"Chicago_White_Sox\"],\n",
    "   [12, \"Toronto_Blue_Jays\"], [13, \"Texas_Rangers_(baseball)\"], [14, \"Minnesota_Twins\"], [15, \"Detroit_Tigers\"],\n",
    "   [16, \"Kansas_City_Royals\"]]\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "C = generate_candidates(S, M, 5)\n",
    "#print C\n",
    "#try:\n",
    "ids, titles = disambiguate_driver(C, 5, 'rvspagerank', 2, 'context4_4')\n",
    "#except:\n",
    "    #print \"Error\"\n",
    "\n",
    "elapsed = str(timeformat(int(time.time()-start)));\n",
    "#print ids\n",
    "#\n",
    "print titles\n",
    "\n",
    "tp = get_tp(M, ids) \n",
    "print tp\n",
    "print elapsed\n",
    "# prec = get_prec(tp)\n",
    "# print prec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cripples wsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "%aimport wsd\n",
    "\n",
    "import sys\n",
    "\n",
    "from wsd import *\n",
    "\n",
    "\n",
    "\n",
    "dsnames = [os.path.join(home,'backup/datasets/ner/kore.json'),\n",
    "          os.path.join(home,'backup/datasets/ner/aida.json'), \n",
    "          os.path.join(home,'backup/datasets/ner/wiki-mentions.5000.json')]\n",
    "\n",
    "#dsnames = [os.path.join(home,'backup/datasets/ner/wiki-mentions.json'), \n",
    "#           os.path.join(home,'backup/datasets/ner/kore.json')]\n",
    "\n",
    "dsnames = [os.path.join(home,'backup/datasets/ner/kore.json')]\n",
    "\n",
    "methods = (('wlm', DIR_IN,'ilp'), ('rvspagerank', DIR_OUT, 'ilp'))\n",
    "\n",
    "methods = (\n",
    "           ('rvspagerank', DIR_OUT, 'context3'),\n",
    "           ('rvspagerank', DIR_OUT, 'context3'),\n",
    "           ('rvspagerank', DIR_OUT, 'context1'))\n",
    "\n",
    "# methods = (('wlm', DIR_IN,'ilp'), ('rvspagerank', DIR_OUT, 'ilp'))\n",
    "#methods = (('wlm', DIR_IN, 'tagme'),)\n",
    "#methods = (('rvspagerank', DIR_BOTH, 'ilp2'), )\n",
    "methods = (('rvspagerank', DIR_BOTH, 'pkeyq'), )\n",
    "\n",
    "max_t=5\n",
    "max_count=-1\n",
    "ws=5\n",
    "verbose=True\n",
    "restart = True\n",
    "\n",
    "outdir = os.path.join(baseresdir, 'wsd')\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)\n",
    "    \n",
    "resname =  os.path.join(outdir, 'reslog.txt')\n",
    "#clearlog(resname)\n",
    "\n",
    "detailedresname=  os.path.join(outdir, 'detailedreslog.txt')\n",
    "#clearlog(detailedresname)\n",
    "\n",
    "\n",
    "for method, direction, op_method in methods:\n",
    "    for dsname in dsnames:\n",
    "        start = time.time()\n",
    "        \n",
    "        print \"dsname: %s, method: %s, op_method: %s, direction: %s, max_t: %s, ws: %s ...\"  % (dsname,\n",
    "                method, op_method, direction, max_t, ws)\n",
    "        sys.stdout.flush()\n",
    "        tmpfilename = os.path.join(outdir, \n",
    "                                   '-'.join([method, str(direction), op_method, str(max_t), str(ws), os.path.basename(dsname)]))\n",
    "        \n",
    "        overall=[]\n",
    "        start_count=-1\n",
    "        if os.path.isfile(tmpfilename):\n",
    "            if restart:\n",
    "                os.remove(tmpfilename)\n",
    "            else:\n",
    "                with open(tmpfilename,'r') as tmpf:\n",
    "                    for line in tmpf:\n",
    "                        js = json.loads(line.strip())\n",
    "                        start_count = js['no']\n",
    "                        if js['tp'] is not None:\n",
    "                            overall.append(js['tp'])\n",
    "        \n",
    "        if start_count !=-1:\n",
    "            print \"Continuing from\\t\", start_count\n",
    "        count=0\n",
    "        with open(dsname,'r') as ds, open(tmpfilename,'a') as tmpf:\n",
    "            for line in ds:\n",
    "                js = json.loads(line.decode('utf-8').strip());\n",
    "                S = js[\"text\"]\n",
    "                M = js[\"mentions\"]\n",
    "                count +=1\n",
    "                if count <= start_count:\n",
    "                    continue\n",
    "                if verbose:\n",
    "                    print \"%s:\\tS=%s\\n\\tM=%s\" % (count, json.dumps(S, ensure_ascii=False),json.dumps(M, ensure_ascii=False))\n",
    "                    sys.stdout.flush()\n",
    "                    \n",
    "                C = generate_candidates(S, M, max_t=max_t, enforce=True)\n",
    "                try:\n",
    "                    ids, titles = disambiguate_driver(C, ws, method, direction, op_method)\n",
    "                except:\n",
    "                    print \"Error\"\n",
    "                    tmpf.write(json.dumps({\"no\":count, \"tp\":None})+\"\\n\")\n",
    "                    continue\n",
    "                    \n",
    "                tp = get_tp(M, ids) \n",
    "                overall.append(tp)\n",
    "                tmpf.write(json.dumps({\"no\":count, \"tp\":tp})+\"\\n\")\n",
    "                if (max_count !=-1) and (count >= max_count):\n",
    "                    break\n",
    "                    \n",
    "\n",
    "        elapsed = str(timeformat(int(time.time()-start)));\n",
    "        print \"done\"\n",
    "        detailedres ={\"dsname\":dsname, \"method\": method, \"op_method\": op_method, \"driection\": direction,\n",
    "                      \"max_t\": max_t, \"tp\":overall, \"elapsed\": elapsed, \"ws\": ws}\n",
    "        \n",
    "        \n",
    "        #logres(detailedresname, '%s',  json.dumps(detailedres))\n",
    "        #print('%s',  json.dumps(detailedres))\n",
    "        \n",
    "        micro_prec, macro_prec = get_prec(overall)        \n",
    "        #logres(resname, '%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s', method, op_method, graphtype(direction), max_t , ws, \n",
    "               #dsname, micro_prec, macro_prec, elapsed)\n",
    "        print '%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s'% (method, op_method, graphtype(direction), max_t , ws, \n",
    "               dsname, micro_prec, macro_prec, elapsed)\n",
    "\n",
    "print \"done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "wlm\ttagme\tin\t20\t5\t/home/sajadi/backup/datasets/ner/wiki-mentions.json\t0.607142857143\t0.58427045177\t0:05:47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload\n",
    "\n",
    "# %aimport wsd\n",
    "# import sys\n",
    "from wsd import *\n",
    "import time\n",
    "S=[\"Major League Baseball\", \"New York City\", \"Major League Baseball\", \"American League\",\n",
    "            \"Boston Red Sox\", \"Seattle Mariners\", \"Cleveland Indians\", \"Milwaukee Brewers\", \"Baltimore Orioles\",\n",
    "            \"Oakland Athletics\", \"New York Yankees\", \"Chicago White Sox\", \"Toronto Blue Jays\", \"Texas Rangers\", \n",
    "            \"Minnesota Twins\", \"Detroit Tigers\", \"Kansas City Royals\"]\n",
    "M=[[0, \"Major_League_Baseball\"], [1, \"New_York_City\"], [2, \"Major_League_Baseball\"], [3, \"American_League\"],\n",
    "   [4, \"Boston_Red_Sox\"], [5, \"Seattle_Mariners\"], [6, \"Cleveland_Indians\"], [7, \"Milwaukee_Brewers\"],\n",
    "   [8, \"Baltimore_Orioles\"], [9, \"Oakland_Athletics\"], [10, \"New_York_Yankees\"], [11, \"Chicago_White_Sox\"],\n",
    "   [12, \"Toronto_Blue_Jays\"], [13, \"Texas_Rangers_(baseball)\"], [14, \"Minnesota_Twins\"], [15, \"Detroit_Tigers\"],\n",
    "   [16, \"Kansas_City_Royals\"]]\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "cvec_arr, cveclist_bdrs, key_concept, key_entity, key_entity_vector = find_key_concept(candslist, direction, method, ver)\n",
    "#print C\n",
    "#try:\n",
    "ids, titles = disambiguate_driver(C, 5, 'rvspagerank', 2, 'context4_4')\n",
    "#except:\n",
    "    #print \"Error\"\n",
    "\n",
    "elapsed = str(timeformat(int(time.time()-start)));\n",
    "#print ids\n",
    "#\n",
    "print titles\n",
    "\n",
    "tp = get_tp(M, ids) \n",
    "print tp\n",
    "print elapsed\n",
    "# prec = get_prec(tp)\n",
    "# print prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "{\"text\": [\"Tiger\", \"lost\", \"the\", \"US Open\", \".\"], \"mentions\": [[0, \"Tiger_Woods\"], [3, \"U.S._Open_(golf)\"]]}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
